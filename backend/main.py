# COMPLETE main.py - ALL FUNCTIONALITY PRESERVED + UNLIMITED FETCHING
import asyncio
import json
import logging
import math
import os
import re
import time
import traceback
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional

import aiohttp
import pyodbc
import requests
from ai_status import check_azure_ai_configuration
from database_azure_fixed import save_legislation_to_azure_sql, test_azure_sql_connection
from database_connection import execute_query, get_database_connection, get_db_cursor, test_database_connection
from dotenv import load_dotenv
from executive_orders_db import (
    add_highlight_direct, create_highlights_table, get_executive_order_by_number,
    get_executive_orders_from_db, get_user_highlights_direct, remove_highlight_direct,
    save_executive_orders_to_db, update_executive_order_category_in_db, get_database_count
)
from fastapi import BackgroundTasks, FastAPI, HTTPException, Path, Query, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

load_dotenv(override=True)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===============================
# ENHANCED AI INTEGRATION
# ===============================
try:
    from openai import AsyncAzureOpenAI
    OPENAI_AVAILABLE = True
    logger.info("‚úÖ OpenAI library available")
except ImportError:
    logger.warning("‚ùå OpenAI library not available - install with: pip install openai")
    OPENAI_AVAILABLE = False

# Configuration
AZURE_ENDPOINT = os.getenv("AZURE_ENDPOINT", "https://david-mabholqy-swedencentral.openai.azure.com/")
AZURE_KEY = os.getenv("AZURE_KEY")
MODEL_NAME = os.getenv("AZURE_MODEL_NAME", "summarize-gpt-4.1")
LEGISCAN_API_KEY = os.getenv('LEGISCAN_API_KEY')

# Initialize Enhanced Azure OpenAI client
enhanced_ai_client = None
if OPENAI_AVAILABLE and AZURE_KEY:
    try:
        enhanced_ai_client = AsyncAzureOpenAI(
            azure_endpoint=AZURE_ENDPOINT,
            api_key=AZURE_KEY,
            api_version="2024-12-01-preview"
        )
        logger.info("‚úÖ Enhanced AI client initialized successfully")
    except Exception as e:
        logger.warning(f"‚ùå Enhanced AI client initialization failed: {e}")

# Enhanced Enums
class PromptType(Enum):
    EXECUTIVE_SUMMARY = "executive_summary"
    KEY_TALKING_POINTS = "key_talking_points"
    BUSINESS_IMPACT = "business_impact"

class BillCategory(Enum):
    HEALTHCARE = "healthcare"
    EDUCATION = "education"
    ENGINEERING = "engineering"
    CIVIC = "civic"
    NOT_APPLICABLE = "not_applicable"
    ALL_PRACTICE_AREAS = "all_practice_areas"

# Enhanced prompt templates
ENHANCED_PROMPTS = {
    PromptType.EXECUTIVE_SUMMARY: """
    Write a concise executive summary of this legislative content in 2-4 sentences. 
    Focus on:
    - What the legislation does (main purpose)
    - Who it affects (target audience/stakeholders)
    - Key changes or requirements it establishes
    
    Use clear, professional language suitable for executives and decision-makers.
    Do NOT use bullet points or lists - write in paragraph form.
    
    Legislative Content: {text}
    """,
    
    PromptType.KEY_TALKING_POINTS: """
    Create exactly 5 distinct talking points for stakeholder discussions about this legislation.
    Each point should be ONE complete sentence and focus on different aspects:

    1. [Main purpose/goal of the legislation]
    2. [Key stakeholders or groups affected]  
    3. [Most significant change or requirement]
    4. [Implementation timeline or process]
    5. [Expected outcomes or benefits]

    Format as numbered list exactly as shown above.
    Make each point actionable for conversations with colleagues, clients, or stakeholders.
    Use bold formatting for important terms: **term**
    
    Legislative Content: {text}
    """,
    
    PromptType.BUSINESS_IMPACT: """
    Analyze the business impact of this legislation using clear, professional language:

    Risk Assessment:
    Regulatory and Market Uncertainty
    ‚Ä¢ [Describe the main regulatory risk in one clear sentence]
    ‚Ä¢ [Describe the market uncertainty risk in one clear sentence]

    Market Opportunity:
    Increased Investment and Demand
    ‚Ä¢ [Describe the main business opportunity in one clear sentence]  
    ‚Ä¢ [Describe specific benefits available in one clear sentence]

    Summary:
    [Provide a balanced 1-2 sentence summary of the overall business impact]

    Use simple bullet points with ‚Ä¢ character only. 
    Avoid asterisks (**) and dashes (---) in your response.
    Focus on concrete business implications.

    Legislative Content: {text}
    """
}

# Enhanced system messages
ENHANCED_SYSTEM_MESSAGES = {
    PromptType.EXECUTIVE_SUMMARY: "You are a senior policy analyst who writes clear, concise executive summaries for C-level executives. Focus on the big picture and strategic implications.",
    PromptType.KEY_TALKING_POINTS: "You are a communications strategist helping leaders discuss policy changes. Create talking points that are memorable, accurate, and useful for stakeholder conversations.",
    PromptType.BUSINESS_IMPACT: "You are a business strategy consultant analyzing regulatory impact. Focus on concrete business implications, compliance requirements, and strategic opportunities.",
}

# Supported states
SUPPORTED_STATES = {
    "California": "CA",
    "Colorado": "CO", 
    "Kentucky": "KY",
    "Nevada": "NV",
    "South Carolina": "SC",
    "Texas": "TX",
}

# ===============================
# REQUEST MODELS
# ===============================
class CategoryUpdateRequest(BaseModel):
    category: str

class ReviewUpdateRequest(BaseModel):
    reviewed: bool

class ExecutiveOrderFetchRequest(BaseModel):
    start_date: Optional[str] = "2025-01-20"
    end_date: Optional[str] = None
    per_page: Optional[int] = 10000  # UNLIMITED: Use maximum
    save_to_db: Optional[bool] = True
    with_ai: Optional[bool] = True

class ExecutiveOrderSearchRequest(BaseModel):
    category: Optional[str] = None
    search: Optional[str] = None
    page: int = 1
    per_page: int = 1000
    sort_by: str = "signing_date"
    sort_order: str = "desc"
    user_id: Optional[str] = None

class HighlightCreateRequest(BaseModel):
    user_id: int
    order_id: str
    order_type: str  # 'executive_order' or 'state_legislation'
    notes: Optional[str] = None
    priority_level: Optional[int] = 1
    tags: Optional[str] = None
    is_archived: Optional[bool] = False

class HighlightUpdateRequest(BaseModel):
    user_id: int
    notes: Optional[str] = None
    priority_level: Optional[int] = None
    tags: Optional[str] = None
    is_archived: Optional[bool] = None

class StateLegislationFetchRequest(BaseModel):
    states: List[str]
    save_to_db: bool = True
    bills_per_state: int = 25

class LegiScanSearchRequest(BaseModel):
    query: str
    state: str
    limit: int = 20
    save_to_db: bool = True
    process_one_by_one: bool = False
    with_ai_analysis: bool = True
    enhanced_ai: bool = True

# ===============================
# DATABASE SETUP
# ===============================
AZURE_SQL_AVAILABLE = True
HIGHLIGHTS_DB_AVAILABLE = True
EXECUTIVE_ORDERS_AVAILABLE = True

# Simple Executive Orders integration
try:
    from simple_executive_orders import fetch_executive_orders_simple_integration
    SIMPLE_EO_AVAILABLE = True
    logger.info("‚úÖ Simple Executive Orders API available")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Simple Executive Orders API not available: {e}")
    SIMPLE_EO_AVAILABLE = False

# LegiScan API integration
try:
    from legiscan_api import LegiScanAPI
    LEGISCAN_AVAILABLE = True
    logger.info("‚úÖ LegiScan API imported successfully")
    
    try:
        test_legiscan = LegiScanAPI()
        logger.info("‚úÖ LegiScan API can be initialized")
        LEGISCAN_INITIALIZED = True
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è LegiScan API import successful but initialization failed: {e}")
        LEGISCAN_INITIALIZED = False
        
except ImportError as e:
    logger.warning(f"‚ùå LegiScan API import failed: {e}")
    LEGISCAN_AVAILABLE = False
    LEGISCAN_INITIALIZED = False

# ===============================
# UNLIMITED FEDERAL REGISTER FETCH
# ===============================
async def get_federal_register_count():
    """Get total count from Federal Register API without fetching all data"""
    try:
        base_url = "https://www.federalregister.gov/api/v1"
        
        start_date = "01/20/2025"
        end_date = datetime.now().strftime('%m/%d/%Y')
        
        base_params = {
            'conditions[correction]': '0',
            'conditions[president]': 'donald-trump',
            'conditions[presidential_document_type]': 'executive_order',
            'conditions[signing_date][gte]': start_date,
            'conditions[signing_date][lte]': end_date,
            'conditions[type][]': 'PRESDOCU',
            'fields[]': ['document_number'],
            'include_pre_1994_docs': 'true',
            'maximum_per_page': '10000',  # UNLIMITED
            'order': 'executive_order',
            'per_page': '1'
        }
        
        response = requests.get(f"{base_url}/documents.json", params=base_params, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            total_count = data.get('count', 0)
            logger.info(f"üìä Federal Register reports {total_count} total executive orders")
            return total_count
        else:
            logger.error(f"‚ùå Federal Register API error: {response.status_code}")
            return 0
            
    except Exception as e:
        logger.error(f"‚ùå Error getting Federal Register count: {e}")
        return 0

async def get_database_count():
    """Get total count from database"""
    try:
        conn = get_database_connection()
        cursor = conn.cursor()
        
        # FIXED: Remove president filter - just count all executive orders
        cursor.execute("SELECT COUNT(*) FROM dbo.executive_orders")
        
        count = cursor.fetchone()[0]
        cursor.close()
        conn.close()
        
        logger.info(f"üìä Database has {count} executive orders")
        return count
        
    except Exception as e:
        logger.error(f"‚ùå Error getting database count: {e}")
        return 0

async def fetch_all_executive_orders_unlimited() -> Dict:
    """
    UNLIMITED: Fetch ALL executive orders from Federal Register API with NO LIMITS
    """
    try:
        logger.info("üöÄ Fetching ALL Executive Orders from Federal Register (UNLIMITED)")
        
        base_url = "https://www.federalregister.gov/api/v1/documents.json"
        
        # UNLIMITED parameters - use maximum allowed by API
        base_params = {
            'conditions[correction]': '0',
            'conditions[president]': 'donald-trump',
            'conditions[presidential_document_type]': 'executive_order',
            'conditions[signing_date][gte]': '01/20/2025',
            'conditions[signing_date][lte]': datetime.now().strftime('%m/%d/%Y'),
            'conditions[type][]': 'PRESDOCU',
            'fields[]': [
                'citation', 'document_number', 'html_url', 'pdf_url', 'type',
                'subtype', 'publication_date', 'signing_date', 'title',
                'executive_order_number', 'full_text_xml_url', 'body_html_url',
                'json_url', 'abstract'
            ],
            'include_pre_1994_docs': 'true',
            'maximum_per_page': '10000',  # UNLIMITED: Maximum allowed
            'per_page': '10000',          # UNLIMITED: Maximum allowed
            'order': 'executive_order'
        }
        
        all_orders = []
        page = 1
        
        # UNLIMITED: Keep fetching until we have ALL orders
        while True:
            params = base_params.copy()
            params['page'] = page
            
            logger.info(f"üîÑ Fetching page {page} from Federal Register API...")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(base_url, params=params, timeout=60) as response:
                    response.raise_for_status()
                    data = await response.json()
                    
                    results = data.get('results', [])
                    count = data.get('count', 0)
                    total_pages = data.get('total_pages', 1)
                    
                    logger.info(f"üìÑ Page {page}: Got {len(results)} orders, Total available: {count}")
                    
                    if not results:
                        logger.info("üîö No more results, breaking pagination loop")
                        break
                    
                    # Process and add orders
                    for order in results:
                        processed_order = {
                            'document_number': order.get('document_number', ''),
                            'eo_number': order.get('executive_order_number', ''),
                            'executive_order_number': order.get('executive_order_number', ''),
                            'title': order.get('title', ''),
                            'summary': order.get('abstract', ''),
                            'description': order.get('abstract', ''),
                            'signing_date': order.get('signing_date', ''),
                            'publication_date': order.get('publication_date', ''),
                            'citation': order.get('citation', ''),
                            'presidential_document_type': order.get('type', 'executive_order'),
                            'html_url': order.get('html_url', ''),
                            'pdf_url': order.get('pdf_url', ''),
                            'trump_2025_url': order.get('html_url', ''),
                            'full_text_xml_url': order.get('full_text_xml_url', ''),
                            'body_html_url': order.get('body_html_url', ''),
                            'json_url': order.get('json_url', ''),
                            'category': 'civic',
                            'source': 'Federal Register API',
                            'president': 'donald-trump',
                            'raw_data_available': True,
                            'processing_status': 'fetched',
                            'created_at': datetime.now().isoformat(),
                            'last_updated': datetime.now().isoformat()
                        }
                        all_orders.append(processed_order)
                    
                    # Check if we've reached the end
                    if page >= total_pages:
                        logger.info(f"üîö Reached final page {page} of {total_pages}")
                        break
                    
                    page += 1
                    await asyncio.sleep(0.5)
        
        logger.info(f"‚úÖ UNLIMITED FETCH COMPLETE: Retrieved {len(all_orders)} total executive orders")
        
        return {
            'success': True,
            'results': all_orders,
            'count': len(all_orders),
            'total_found': len(all_orders),
            'pages_fetched': page - 1,
            'method': 'unlimited_federal_register_fetch',
            'date_range_used': f"01/20/2025 to {datetime.now().strftime('%m/%d/%Y')}",
            'message': f"Successfully fetched all {len(all_orders)} executive orders with no limits"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in unlimited fetch: {e}")
        return {
            'success': False,
            'error': str(e),
            'results': [],
            'count': 0
        }

# ===============================
# ENHANCED AI PROCESSING
# ===============================
def clean_summary_format(text: str) -> str:
    """Clean and format executive summary"""
    if not text:
        return "<p>No summary available</p>"
    
    text = re.sub(r'^\s*[‚Ä¢\-\*]\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s*', '', text, flags=re.MULTILINE)
    
    sentences = text.strip().split('. ')
    
    if len(sentences) <= 3:
        return f"<p>{'. '.join(sentences)}</p>"
    else:
        mid = len(sentences) // 2
        para1 = '. '.join(sentences[:mid]) + '.'
        para2 = '. '.join(sentences[mid:])
        return f"<p>{para1}</p><p>{para2}</p>"

def format_talking_points(text: str) -> str:
    """Format talking points as proper numbered list"""
    if not text:
        return "<p>No talking points available</p>"
    
    lines = text.strip().split('\n')
    points = []
    
    for line in lines:
        line = line.strip()
        if re.match(r'^\d+\.', line):
            content = re.sub(r'^\d+\.\s*', '', line)
            if content:
                points.append(content)
    
    if len(points) < 5:
        while len(points) < 5:
            points.append("Additional analysis point to be determined based on further review.")
    
    points = points[:5]
    
    html_points = []
    for i, point in enumerate(points, 1):
        point = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', point)
        html_points.append(f"<li><strong>{i}.</strong> {point}</li>")
    
    return f"<ol class='talking-points'>{' '.join(html_points)}</ol>"

def format_business_impact(text: str) -> str:
    """Format business impact with clean, professional structure"""
    if not text:
        return "<p>No business impact analysis available</p>"
    
    text = re.sub(r'^---+\s*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', text)
    text = re.sub(r'^\*\*([^*]+):\*\*', r'<strong>\1:</strong>', text, flags=re.MULTILINE)
    
    sections = {
        'risk': [],
        'opportunity': [],
        'summary': []
    }
    
    current_section = None
    lines = text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or line == '---':
            continue
            
        line_lower = line.lower()
        if any(keyword in line_lower for keyword in ['risk', 'regulatory and market uncertainty']):
            current_section = 'risk'
            if ':' in line and line.split(':', 1)[1].strip():
                content = line.split(':', 1)[1].strip()
                if content:
                    sections[current_section].append(content)
            continue
        elif any(keyword in line_lower for keyword in ['opportunity', 'increased investment', 'market opportunity']):
            current_section = 'opportunity'
            if ':' in line and line.split(':', 1)[1].strip():
                content = line.split(':', 1)[1].strip()
                if content:
                    sections[current_section].append(content)
            continue
        elif any(keyword in line_lower for keyword in ['summary']):
            current_section = 'summary'
            if ':' in line and line.split(':', 1)[1].strip():
                content = line.split(':', 1)[1].strip()
                if content:
                    sections[current_section].append(content)
            continue
        
        if line.startswith('‚Ä¢') or line.startswith('-') or line.startswith('*'):
            bullet_content = re.sub(r'^[‚Ä¢\-*]\s*', '', line).strip()
            if bullet_content and current_section:
                sections[current_section].append(bullet_content)
        elif current_section and line and not line.startswith('**'):
            sections[current_section].append(line)
    
    html_parts = []
    
    if sections['risk']:
        html_parts.append('<div class="business-impact-section risk-section">')
        html_parts.append('<h4>Risk Assessment</h4>')
        html_parts.append('<div class="risk-content">')
        
        for item in sections['risk'][:3]:
            clean_item = re.sub(r'^[‚Ä¢\-*]\s*', '', item).strip()
            clean_item = re.sub(r'^\*\*([^*]+):\*\*\s*', r'<strong>\1:</strong> ', clean_item)
            
            if clean_item:
                html_parts.append(f'<p>‚Ä¢ {clean_item}</p>')
        
        html_parts.append('</div></div>')
    
    if sections['opportunity']:
        html_parts.append('<div class="business-impact-section opportunity-section">')
        html_parts.append('<h4>Market Opportunity</h4>')
        html_parts.append('<div class="opportunity-content">')
        
        for item in sections['opportunity'][:3]:
            clean_item = re.sub(r'^[‚Ä¢\-*]\s*', '', item).strip()
            clean_item = re.sub(r'^\*\*([^*]+):\*\*\s*', r'<strong>\1:</strong> ', clean_item)
            
            if clean_item:
                html_parts.append(f'<p>‚Ä¢ {clean_item}</p>')
        
        html_parts.append('</div></div>')
    
    if sections['summary']:
        html_parts.append('<div class="business-impact-section summary-section">')
        html_parts.append('<h4>Summary</h4>')
        html_parts.append('<div class="summary-content">')
        
        for item in sections['summary'][:2]:
            clean_item = re.sub(r'^[‚Ä¢\-*]\s*', '', item).strip()
            clean_item = re.sub(r'^\*\*([^*]+):\*\*\s*', r'<strong>\1:</strong> ', clean_item)
            
            if clean_item:
                html_parts.append(f'<p>{clean_item}</p>')
        
        html_parts.append('</div></div>')
    
    return ''.join(html_parts) if html_parts else '<p>Business impact analysis processing...</p>'

def categorize_bill_enhanced(title: str, description: str) -> BillCategory:
    """Enhanced bill categorization"""
    content = f"{title} {description}".lower().strip()
    
    if not content:
        return BillCategory.NOT_APPLICABLE
    
    # Check for "all practice areas" keywords
    if any(word in content for word in ['all practice', 'multiple area', 'cross-disciplinary', 'interdisciplinary']):
        return BillCategory.ALL_PRACTICE_AREAS
    elif any(word in content for word in ['health', 'medical', 'healthcare', 'medicine', 'hospital', 'patient', 'medicare', 'medicaid']):
        return BillCategory.HEALTHCARE
    elif any(word in content for word in ['education', 'school', 'student', 'university', 'college', 'learning', 'teacher']):
        return BillCategory.EDUCATION
    elif any(word in content for word in ['infrastructure', 'engineering', 'construction', 'bridge', 'road', 'technology', 'broadband']):
        return BillCategory.ENGINEERING
    elif any(word in content for word in ['government', 'federal', 'agency', 'department', 'administration', 'policy', 'regulation', 'civic']):
        return BillCategory.CIVIC
    else:
        return BillCategory.NOT_APPLICABLE

async def enhanced_ai_analysis(text: str, prompt_type: PromptType, temperature: float = 0.1, context: str = "") -> str:
    """Enhanced AI processing with distinct prompts and formatting"""
    try:
        if not enhanced_ai_client:
            return f"<p>AI client not available for {prompt_type.value}</p>"
        
        max_input_length = 4000
        if len(text) > max_input_length:
            text = text[:max_input_length] + "..."
        
        if context:
            text = f"Context: {context}\n\n{text}"
        
        prompt = ENHANCED_PROMPTS[prompt_type].format(text=text)
        
        messages = [
            {"role": "system", "content": ENHANCED_SYSTEM_MESSAGES[prompt_type]},
            {"role": "user", "content": prompt}
        ]

        if prompt_type == PromptType.EXECUTIVE_SUMMARY:
            max_tokens = 300
            temperature = 0.1
        elif prompt_type == PromptType.KEY_TALKING_POINTS:
            max_tokens = 400
            temperature = 0.2
        elif prompt_type == PromptType.BUSINESS_IMPACT:
            max_tokens = 500
            temperature = 0.15
        
        response = await enhanced_ai_client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=30,
            top_p=0.95,
            frequency_penalty=0.3,
            presence_penalty=0.2,
            stop=["6.", "7.", "8.", "9."] if prompt_type == PromptType.KEY_TALKING_POINTS else None
        )

        raw_response = response.choices[0].message.content

        # Enhanced formatting for each type
        if prompt_type == PromptType.EXECUTIVE_SUMMARY:
            formatted_response = clean_summary_format(raw_response)
        elif prompt_type == PromptType.KEY_TALKING_POINTS:
            formatted_response = format_talking_points(raw_response)
        elif prompt_type == PromptType.BUSINESS_IMPACT:
            formatted_response = format_business_impact(raw_response)
        else:
            formatted_response = f"<p>{raw_response}</p>"

        return formatted_response

    except Exception as e:
        logger.error(f"‚ùå Error during enhanced AI {prompt_type.value} call: {e}")
        return f"<p>Error generating {prompt_type.value.replace('_', ' ')}: {str(e)}</p>"

async def enhanced_bill_analysis(bill_data: Dict, context: str = "") -> Dict[str, str]:
    """Comprehensive AI analysis of a bill with enhanced distinct content"""
    try:
        title = bill_data.get('title', '')
        description = bill_data.get('description', '')
        bill_number = bill_data.get('bill_number', '')
        state = bill_data.get('state', '')
        session = bill_data.get('session', {})
        session_name = session.get('session_name', '') if isinstance(session, dict) else ''
        sponsors = bill_data.get('sponsors', [])
        
        base_context = f"{state} {bill_number}" if state and bill_number else "State Legislation"
        
        content_parts = []
        if title:
            content_parts.append(f"Title: {title}")
        if state:
            content_parts.append(f"State: {state}")
        if bill_number:
            content_parts.append(f"Bill Number: {bill_number}")
        if description:
            content_parts.append(f"Description: {description}")
        if session_name:
            content_parts.append(f"Legislative Session: {session_name}")
        if sponsors and len(sponsors) > 0:
            sponsor_names = []
            for sponsor in sponsors[:3]:
                if isinstance(sponsor, dict):
                    name = sponsor.get('name', '')
                    if name:
                        sponsor_names.append(name)
            if sponsor_names:
                content_parts.append(f"Primary Sponsors: {', '.join(sponsor_names)}")
        
        content = "\n\n".join(content_parts)
        
        category = categorize_bill_enhanced(title, description)
        
        try:
            summary_task = enhanced_ai_analysis(content, PromptType.EXECUTIVE_SUMMARY, context=f"Executive Summary - {base_context}")
            talking_points_task = enhanced_ai_analysis(content, PromptType.KEY_TALKING_POINTS, context=f"Stakeholder Discussion - {base_context}")
            business_impact_task = enhanced_ai_analysis(content, PromptType.BUSINESS_IMPACT, context=f"Business Analysis - {base_context}")
            
            summary_result, talking_points_result, business_impact_result = await asyncio.gather(
                summary_task, talking_points_task, business_impact_task, return_exceptions=True
            )
            
            if isinstance(summary_result, Exception):
                summary_result = f"<p>Error generating summary: {str(summary_result)}</p>"
            if isinstance(talking_points_result, Exception):
                talking_points_result = f"<p>Error generating talking points: {str(talking_points_result)}</p>"
            if isinstance(business_impact_result, Exception):
                business_impact_result = f"<p>Error generating business impact: {str(business_impact_result)}</p>"
                
        except Exception as e:
            logger.error(f"‚ùå Error in enhanced AI analysis tasks: {e}")
            summary_result = f"<p>Error generating summary: {str(e)}</p>"
            talking_points_result = f"<p>Error generating talking points: {str(e)}</p>"
            business_impact_result = f"<p>Error generating business impact: {str(e)}</p>"
        
        return {
            'ai_summary': summary_result,
            'ai_executive_summary': summary_result,
            'ai_talking_points': talking_points_result,
            'ai_key_points': talking_points_result,
            'ai_business_impact': business_impact_result,
            'ai_potential_impact': business_impact_result,
            'category': category.value,
            'ai_version': 'enhanced_azure_openai_v2',
            'analysis_timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in enhanced bill analysis: {e}")
        error_msg = f"<p>Enhanced AI analysis failed: {str(e)}</p>"
        return {
            'ai_summary': error_msg,
            'ai_executive_summary': error_msg,
            'ai_talking_points': error_msg,
            'ai_key_points': error_msg,
            'ai_business_impact': error_msg,
            'ai_potential_impact': error_msg,
            'category': BillCategory.NOT_APPLICABLE.value,
            'ai_version': 'error',
            'analysis_timestamp': datetime.now().isoformat()
        }

# ===============================
# ENHANCED LEGISCAN CLIENT
# ===============================
class EnhancedLegiScanClient:
    """Enhanced LegiScan client with comprehensive AI integration"""
    
    def __init__(self, api_key: str = None, rate_limit_delay: float = 0.5):
        self.api_key = api_key or LEGISCAN_API_KEY
        self.rate_limit_delay = rate_limit_delay
        self.base_url = "https://api.legiscan.com"
        
        if not self.api_key:
            raise ValueError("LegiScan API key is required")
    
    def _build_url(self, operation: str, params: Optional[Dict] = None) -> str:
        """Build LegiScan API URL"""
        if params is None:
            params = {}
        
        param_str = '&'.join([f"{k}={v}" for k, v in params.items()])
        return f"{self.base_url}/?key={self.api_key}&op={operation}&{param_str}"
    
    async def _api_request(self, url: str) -> Dict[str, Any]:
        """Make async API request with error handling"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    response.raise_for_status()
                    data = await response.json()
                    
                    if data.get('status') == "ERROR":
                        error_msg = data.get('alert', {}).get('message', 'Unknown API error')
                        raise Exception(f"LegiScan API Error: {error_msg}")
                    
                    await asyncio.sleep(self.rate_limit_delay)
                    return data
                    
        except Exception as e:
            logger.error(f"‚ùå Enhanced LegiScan API request failed: {e}")
            raise
    
    async def search_bills_enhanced(self, state: str, query: str, limit: int = 20) -> Dict:
        """Enhanced bill search with comprehensive data"""
        try:
            params = {'query': query, 'year': 2, 'page': 1}
            if state:
                params['state'] = state
            
            url = self._build_url('search', params)
            data = await self._api_request(url)
            search_result = data.get('searchresult', {})
            
            summary = search_result.pop('summary', {})
            results = [search_result[key] for key in search_result if key != 'summary']
            
            if limit and len(results) > limit:
                results = results[:limit]
            
            return {
                'success': True,
                'summary': summary,
                'results': results,
                'bills_found': len(results)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in enhanced search: {e}")
            return {
                'success': False,
                'error': str(e),
                'results': []
            }
    
    async def get_bill_detailed(self, bill_id: int) -> Dict:
        """Get detailed bill information"""
        try:
            url = self._build_url('getBill', {'id': bill_id})
            data = await self._api_request(url)
            
            bill = data.get('bill', {})
            return bill
            
        except Exception as e:
            logger.error(f"‚ùå Error fetching detailed bill {bill_id}: {e}")
            return {}
    
    async def enhanced_search_and_analyze(self, state: str, query: str, limit: int = 20, 
                                        with_ai: bool = True, db_manager = None) -> Dict:
        """Enhanced search and analyze workflow with one-by-one processing"""
        try:
            search_result = await self.search_bills_enhanced(state, query, limit)
            
            if not search_result.get('success') or not search_result.get('results'):
                return {
                    'success': False,
                    'error': 'No bills found for search query',
                    'bills': []
                }
            
            search_results = search_result['results']
            analyzed_bills = []
            
            for i, bill_summary in enumerate(search_results, 1):
                try:
                    bill_id = bill_summary.get('bill_id')
                    if not bill_id:
                        continue
                    
                    detailed_bill = await self.get_bill_detailed(int(bill_id))
                    if not detailed_bill:
                        continue
                    
                    ai_analysis = {}
                    if with_ai and enhanced_ai_client:
                        try:
                            ai_analysis = await enhanced_bill_analysis(detailed_bill, f"Search: {query}")
                        except Exception as e:
                            logger.warning(f"‚ùå Enhanced AI analysis failed for bill {bill_id}: {e}")
                            ai_analysis = {
                                'ai_summary': f'<p>AI analysis failed: {str(e)}</p>',
                                'ai_talking_points': '<p>AI analysis not available</p>',
                                'ai_business_impact': '<p>AI analysis not available</p>',
                                'category': 'not_applicable',
                                'ai_version': 'error'
                            }
                    
                    complete_bill = {
                        'bill_id': bill_id,
                        'bill_number': detailed_bill.get('bill_number', ''),
                        'title': detailed_bill.get('title', ''),
                        'description': detailed_bill.get('description', ''),
                        'state': state,
                        'state_abbr': state,
                        'status': detailed_bill.get('status', ''),
                        'session_id': detailed_bill.get('session', {}).get('session_id', ''),
                        'session_name': detailed_bill.get('session', {}).get('session_name', ''),
                        'bill_type': detailed_bill.get('bill_type', 'bill'),
                        'body': detailed_bill.get('body', ''),
                        'introduced_date': detailed_bill.get('status_date', ''),
                        'last_action_date': detailed_bill.get('status_date', ''),
                        'legiscan_url': detailed_bill.get('state_link', ''),
                        'pdf_url': '',
                        'sponsors': detailed_bill.get('sponsors', []),
                        'committee': detailed_bill.get('committee', []),
                        'history': detailed_bill.get('history', []),
                        'texts': detailed_bill.get('texts', []),
                        'search_query': query,
                        'search_relevance': bill_summary.get('relevance', 0),
                        'source': 'Enhanced LegiScan API',
                        'created_at': datetime.now().isoformat(),
                        'last_updated': datetime.now().isoformat(),
                        'reviewed': False
                    }
                    
                    complete_bill.update(ai_analysis)
                    
                    if db_manager:
                        try:
                            success = db_manager.save_bill(complete_bill)
                            if success:
                                logger.info(f"‚úÖ Saved bill {bill_id} to database")
                        except Exception as e:
                            logger.warning(f"‚ùå Database save error for bill {bill_id}: {e}")
                    
                    analyzed_bills.append(complete_bill)
                    
                except Exception as e:
                    logger.warning(f"‚ùå Error processing bill {i}: {e}")
                    continue
            
            return {
                'success': True,
                'bills': analyzed_bills,
                'bills_found': len(search_results),
                'bills_processed': len(analyzed_bills),
                'query': query,
                'state': state,
                'timestamp': datetime.now().isoformat(),
                'processing_results': {
                    'total_fetched': len(search_results),
                    'total_processed': len(analyzed_bills),
                    'total_saved': len(analyzed_bills) if db_manager else 0,
                    'errors': []
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in enhanced search and analyze: {e}")
            return {
                'success': False,
                'error': str(e),
                'bills': []
            }

# ===============================
# DATABASE HELPERS
# ===============================
class StateLegislationDatabaseManager:
    """Database manager for one-by-one bill processing"""
    
    def __init__(self, connection):
        self.connection = connection
    
    def save_bill(self, bill_data: dict):
        """Save a single bill to the database"""
        try:
            cursor = self.connection.cursor()
            
            check_query = "SELECT id FROM dbo.state_legislation WHERE bill_id = ?"
            cursor.execute(check_query, bill_data.get('bill_id'))
            existing = cursor.fetchone()
            
            if existing:
                update_query = """
                UPDATE dbo.state_legislation SET
                    bill_number = ?, title = ?, description = ?, state = ?, state_abbr = ?,
                    status = ?, category = ?, introduced_date = ?, last_action_date = ?,
                    session_id = ?, session_name = ?, bill_type = ?, body = ?,
                    legiscan_url = ?, pdf_url = ?, ai_summary = ?, ai_executive_summary = ?,
                    ai_talking_points = ?, ai_key_points = ?, ai_business_impact = ?,
                    ai_potential_impact = ?, ai_version = ?, last_updated = ?, reviewed = ?
                WHERE bill_id = ?
                """
                
                values = (
                    bill_data.get('bill_number', ''),
                    bill_data.get('title', ''),
                    bill_data.get('description', ''),
                    bill_data.get('state', ''),
                    bill_data.get('state_abbr', ''),
                    bill_data.get('status', ''),
                    bill_data.get('category', ''),
                    bill_data.get('introduced_date'),
                    bill_data.get('last_action_date'),
                    bill_data.get('session_id', ''),
                    bill_data.get('session_name', ''),
                    bill_data.get('bill_type', ''),
                    bill_data.get('body', ''),
                    bill_data.get('legiscan_url', ''),
                    bill_data.get('pdf_url', ''),
                    bill_data.get('ai_summary', ''),
                    bill_data.get('ai_executive_summary', ''),
                    bill_data.get('ai_talking_points', ''),
                    bill_data.get('ai_key_points', ''),
                    bill_data.get('ai_business_impact', ''),
                    bill_data.get('ai_potential_impact', ''),
                    bill_data.get('ai_version', '1.0'),
                    datetime.utcnow(),
                    bill_data.get('reviewed', False),
                    bill_data.get('bill_id')
                )
                
                cursor.execute(update_query, values)
                
            else:
                insert_query = """
                INSERT INTO dbo.state_legislation (
                    bill_id, bill_number, title, description, state, state_abbr,
                    status, category, introduced_date, last_action_date,
                    session_id, session_name, bill_type, body,
                    legiscan_url, pdf_url, ai_summary, ai_executive_summary,
                    ai_talking_points, ai_key_points, ai_business_impact,
                    ai_potential_impact, ai_version, created_at, last_updated, reviewed
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """
                
                values = (
                    bill_data.get('bill_id', ''),
                    bill_data.get('bill_number', ''),
                    bill_data.get('title', ''),
                    bill_data.get('description', ''),
                    bill_data.get('state', ''),
                    bill_data.get('state_abbr', ''),
                    bill_data.get('status', ''),
                    bill_data.get('category', ''),
                    bill_data.get('introduced_date'),
                    bill_data.get('last_action_date'),
                    bill_data.get('session_id', ''),
                    bill_data.get('session_name', ''),
                    bill_data.get('bill_type', ''),
                    bill_data.get('body', ''),
                    bill_data.get('legiscan_url', ''),
                    bill_data.get('pdf_url', ''),
                    bill_data.get('ai_summary', ''),
                    bill_data.get('ai_executive_summary', ''),
                    bill_data.get('ai_talking_points', ''),
                    bill_data.get('ai_key_points', ''),
                    bill_data.get('ai_business_impact', ''),
                    bill_data.get('ai_potential_impact', ''),
                    bill_data.get('ai_version', '1.0'),
                    datetime.utcnow(),
                    datetime.utcnow(),
                    bill_data.get('reviewed', False)
                )
                
                cursor.execute(insert_query, values)
            
            self.connection.commit()
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error saving bill {bill_data.get('bill_id', 'unknown')}: {e}")
            self.connection.rollback()
            return False

def get_azure_sql_connection():
    """Get Azure SQL connection"""
    try:
        return get_database_connection()
    except Exception as e:
        logger.error(f"‚ùå Azure SQL connection failed: {e}")
        return None

def get_ai_client():
    """Get AI client for bill analysis"""
    try:
        if os.getenv('AZURE_ENDPOINT') and os.getenv('AZURE_KEY'):
            import openai
            client = openai.AzureOpenAI(
                api_key=os.getenv('AZURE_KEY'),
                api_version="2024-02-15-preview",
                azure_endpoint=os.getenv('AZURE_ENDPOINT'),
                azure_deployment=os.getenv('AZURE_MODEL_NAME', 'gpt-4')
            )
            return client
        elif os.getenv('OPENAI_API_KEY'):
            import openai
            client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            return client
        else:
            return None
    except Exception as e:
        logger.error(f"‚ùå AI client setup failed: {e}")
        return None

# ===============================
# STATE LEGISLATION DATABASE FUNCTIONS
# ===============================
def get_state_legislation_from_db(limit=1000, offset=0, filters=None):
    """Get state legislation from Azure SQL database"""
    try:
        base_query = """
            SELECT 
                id, document_number, eo_number, title, summary, 
                signing_date, publication_date, citation, presidential_document_type, category,
                html_url, pdf_url, trump_2025_url, 
                ai_summary, ai_executive_summary, ai_key_points, ai_talking_points, 
                ai_business_impact, ai_potential_impact, ai_version,
                source, raw_data_available, processing_status, error_message,
                created_at, last_updated, last_scraped_at, tags,
                reviewed
            FROM dbo.executive_orders
        """
        
        where_conditions = []
        params = []
        
        if filters:
            if filters.get('state'):
                state_value = filters['state']
                where_conditions.append("(state = ? OR state_abbr = ? OR state LIKE ?)")
                params.extend([state_value, state_value, f"%{state_value}%"])
            
            if filters.get('category'):
                where_conditions.append("category = ?")
                params.append(filters['category'])
            
            if filters.get('search'):
                where_conditions.append("(title LIKE ? OR description LIKE ? OR ai_summary LIKE ?)")
                search_term = f"%{filters['search']}%"
                params.extend([search_term, search_term, search_term])
        
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)
        
        base_query += " ORDER BY last_updated DESC, created_at DESC"
        base_query += f" OFFSET {offset} ROWS FETCH NEXT {limit} ROWS ONLY"
        
        conn = get_azure_sql_connection()
        if not conn:
            return {'success': False, 'message': 'No database connection', 'results': [], 'count': 0}
        
        cursor = conn.cursor()
        
        count_query = "SELECT COUNT(*) FROM dbo.state_legislation"
        if where_conditions:
            count_query += " WHERE " + " AND ".join(where_conditions)
        
        cursor.execute(count_query, params if where_conditions else [])
        total_count = cursor.fetchone()[0]
        
        cursor.execute(base_query, params)
        columns = [desc[0] for desc in cursor.description]
        rows = cursor.fetchall()
        
        results = []
        for i, row in enumerate(rows):
            db_record = dict(zip(columns, row))
            
            api_record = {
                'id': db_record.get('id'),
                'bill_id': db_record.get('bill_id'),
                'bill_number': db_record.get('bill_number'),
                'title': db_record.get('title', 'Untitled Bill'),
                'description': db_record.get('description', ''),
                'summary': db_record.get('ai_summary', ''),
                'state': db_record.get('state', ''),
                'state_abbr': db_record.get('state_abbr', ''),
                'status': db_record.get('status', ''),
                'category': db_record.get('category', 'not-applicable'),
                'session': db_record.get('session_name', ''),
                'bill_type': db_record.get('bill_type', 'bill'),
                'body': db_record.get('body', ''),
                'introduced_date': db_record.get('introduced_date'),
                'last_action_date': db_record.get('last_action_date'),
                'status_date': db_record.get('last_action_date'),
                'legiscan_url': db_record.get('legiscan_url', ''),
                'pdf_url': db_record.get('pdf_url', ''),
                'ai_summary': db_record.get('ai_summary', ''),
                'ai_executive_summary': db_record.get('ai_executive_summary', ''),
                'ai_talking_points': db_record.get('ai_talking_points', ''),
                'ai_key_points': db_record.get('ai_key_points', ''),
                'ai_business_impact': db_record.get('ai_business_impact', ''),
                'ai_potential_impact': db_record.get('ai_potential_impact', ''),
                'ai_version': db_record.get('ai_version', ''),
                'created_at': db_record.get('created_at'),
                'last_updated': db_record.get('last_updated'),
                'source': 'Database',
                'reviewed': db_record.get('reviewed', False)
            }
            
            for date_field in ['introduced_date', 'last_action_date']:
                if api_record.get(date_field):
                    try:
                        if hasattr(api_record[date_field], 'isoformat'):
                            api_record[date_field] = api_record[date_field].isoformat()
                        else:
                            api_record[date_field] = str(api_record[date_field])
                    except:
                        api_record[date_field] = str(api_record[date_field])
            
            results.append(api_record)
        
        cursor.close()
        conn.close()
        
        return {
            'success': True,
            'results': results,
            'count': len(results),
            'total': total_count
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in get_state_legislation_from_db: {e}")
        return {
            'success': False,
            'message': str(e),
            'results': [],
            'count': 0
        }

def save_state_legislation_to_db(bills):
    """Save state legislation to database"""
    try:
        if not AZURE_SQL_AVAILABLE:
            return 0
        
        cleaned_bills = []
        for bill in bills:
            cleaned_bill = dict(bill)
            if 'session' in cleaned_bill:
                del cleaned_bill['session']
            cleaned_bills.append(cleaned_bill)
        
        return save_legislation_to_azure_sql(cleaned_bills)
        
    except Exception as e:
        logger.error(f"‚ùå Error saving state legislation: {e}")
        return 0

def transform_orders_for_save(orders):
    """Transform executive orders for database save with proper field mapping"""
    
    transformed_orders = []
    
    for order in orders:
        # Get the best dates available
        signing_date = order.get('signing_date', '')
        publication_date = order.get('publication_date', '')
        
        # If no signing date, try to use publication date
        if not signing_date and publication_date:
            signing_date = publication_date
        
        # Create clean database record
        transformed_order = {
            'bill_id': f"eo-{order.get('eo_number', 'unknown')}",
            'bill_number': order.get('eo_number', ''),
            'title': order.get('title', ''),
            'description': order.get('summary', ''),
            'state': 'Federal',
            'state_abbr': 'US',
            'status': 'Signed',
            'category': order.get('category', 'civic'),
            'introduced_date': signing_date,  # Use signing_date as introduced_date
            'last_action_date': publication_date or signing_date,  # Use publication_date as last_action
            'session_id': '2025-trump-administration',
            'session_name': 'Trump 2025 Administration',
            'bill_type': 'executive_order',
            'body': 'executive',
            'legiscan_url': order.get('html_url', ''),
            'pdf_url': order.get('pdf_url', ''),
            'ai_summary': order.get('ai_summary', ''),
            'ai_executive_summary': order.get('ai_executive_summary', ''),
            'ai_talking_points': order.get('ai_talking_points', ''),
            'ai_key_points': order.get('ai_key_points', ''),
            'ai_business_impact': order.get('ai_business_impact', ''),
            'ai_potential_impact': order.get('ai_potential_impact', ''),
            'ai_version': order.get('ai_version', 'enhanced_v1'),
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # FIX: Complete the append operation
        transformed_orders.append(transformed_order)
    
    return transformed_orders

# ===============================
# FASTAPI APP SETUP
# ===============================
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown"""
    logger.info("üîÑ Starting Complete LegislationVue API...")
    yield

app = FastAPI(
    title="Complete LegislationVue API - All Features",
    description="API with All Functionality Preserved + Unlimited Fetching",
    version="16.0.0-Complete",
    lifespan=lifespan
)

# Environment detection
raw_env = os.getenv("ENVIRONMENT", "development")
environment = "production" if raw_env == "production" or bool(os.getenv("CONTAINER_APP_NAME") or os.getenv("MSI_ENDPOINT")) else "development"

# CORS setup
frontend_url = os.getenv("FRONTEND_URL", "")
if environment == "production":
    cors_origins = [
        "https://legis-vue-frontend.jollyocean-a8149425.centralus.azurecontainerapps.io",
        "http://legis-vue-frontend.jollyocean-a8149425.centralus.azurecontainerapps.io"
    ]
else:
    cors_origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
    allow_headers=["Content-Type", "Authorization", "X-Requested-With"],
    max_age=86400
)

@app.options("/{path:path}")
async def options_handler(path: str):
    return {}

# ===============================
# CORE API ENDPOINTS
# ===============================
@app.get("/")
async def root():
    """Root endpoint with system status"""
    db_working = False
    try:
        db_working = test_database_connection()
    except:
        pass
    
    return {
        "message": "Complete LegislationVue API - All Features Preserved",
        "status": "healthy",
        "version": "16.0.0-Complete",
        "timestamp": datetime.now().isoformat(),
        "database": {
            "status": "connected" if db_working else "issues",
            "type": "Azure SQL"
        },
        "features": {
            "unlimited_federal_register_fetch": "‚úÖ Active - No 20 order limit",
            "executive_orders_pipeline": "‚úÖ Complete with AI",
            "state_legislation_pipeline": "‚úÖ Complete with Enhanced AI",
            "legiscan_integration": "‚úÖ Traditional + Enhanced",
            "enhanced_ai_processing": "‚úÖ Multi-format analysis",
            "highlights_system": "‚úÖ Full CRUD operations",
            "category_updates": "‚úÖ PATCH endpoints",
            "review_status": "‚úÖ PATCH endpoints",
            "count_checking": "‚úÖ Federal Register vs Database",
            "debug_endpoints": "‚ùå Removed for production"
        },
        "environment": environment,
        "all_functionality_preserved": True
    }

@app.get("/api/status")
async def get_status():
    """Enhanced system status endpoint"""
    try:
        db_working = test_database_connection()
    except:
        db_working = False
    
    azure_sql_working = False
    if AZURE_SQL_AVAILABLE:
        try:
            azure_sql_working = test_azure_sql_connection()
        except:
            pass
    
    return {
        "environment": environment,
        "app_version": "16.0.0-Complete-All-Features",
        "database": {
            "status": "connected" if (db_working or azure_sql_working) else "connection_issues",
            "type": "Azure SQL Database" if AZURE_SQL_AVAILABLE else "Fallback",
            "connection": db_working,
            "azure_sql_connection": azure_sql_working,
            "highlights_enabled": HIGHLIGHTS_DB_AVAILABLE
        },
        "integrations": {
            "simple_executive_orders": "available" if SIMPLE_EO_AVAILABLE else "not_available",
            "azure_sql": "connected" if azure_sql_working else "not_configured",
            "highlights": "available" if HIGHLIGHTS_DB_AVAILABLE else "table_needed",
            "executive_orders_integration": "azure_sql_based" if EXECUTIVE_ORDERS_AVAILABLE else "not_available",
            "legiscan": "connected" if LEGISCAN_INITIALIZED else "not_configured",
            "enhanced_ai_analysis": "connected" if enhanced_ai_client else "not_configured",
            "one_by_one_processing": "available"
        },
        "enhanced_ai_features": {
            "client_available": enhanced_ai_client is not None,
            "model": MODEL_NAME,
            "endpoint": AZURE_ENDPOINT,
            "prompts": list(ENHANCED_PROMPTS.keys()),
            "categories": [cat.value for cat in BillCategory],
            "formatting": ["executive_summary", "talking_points", "business_impact"]
        },
        "features": {
            "unlimited_federal_register": "‚úÖ No 20 order limit - fetch ALL orders",
            "executive_orders_full_pipeline": "‚úÖ Fetch ‚Üí AI ‚Üí Database",
            "state_legislation_enhanced": "‚úÖ LegiScan ‚Üí Enhanced AI ‚Üí Database",
            "persistent_highlights": "‚úÖ Full CRUD with Azure SQL",
            "category_management": "‚úÖ PATCH endpoints for updates",
            "review_status_tracking": "‚úÖ PATCH endpoints for review updates",
            "count_checking": "‚úÖ Federal Register vs Database comparison",
            "enhanced_one_by_one_processing": "‚úÖ Bill-by-bill AI analysis and saving"
        },
        "supported_states": list(SUPPORTED_STATES.keys()),
        "api_keys_configured": {
            "azure_sql": AZURE_SQL_AVAILABLE,
            "legiscan": LEGISCAN_INITIALIZED,
            "enhanced_azure_ai": enhanced_ai_client is not None
        },
        "timestamp": datetime.now().isoformat()
    }

# ===============================
# EXECUTIVE ORDERS ENDPOINTS
# ===============================
@app.get("/api/executive-orders")
async def get_executive_orders_with_highlights(
    page: int = Query(1, ge=1, description="Page number"),
    per_page: int = Query(25, ge=1, le=1000, description="Items per page"),
    category: Optional[str] = Query(None, description="Filter by category"),
    search: Optional[str] = Query(None, description="Search term"),
    limit: Optional[str] = Query(None, description="Special parameter: 'none' to get all records"),
    user_id: Optional[str] = Query(None, description="User ID to show highlight status")
):
    """Get executive orders with highlighting, pagination, and validation - FIXED to include reviewed field"""
    
    try:
        logger.info(f"üîç Getting executive orders - page: {page}, per_page: {per_page}, limit: {limit}")
        
        if not EXECUTIVE_ORDERS_AVAILABLE:
            logger.warning("Executive orders functionality not available")
            return {
                "results": [],
                "count": 0,
                "total_pages": 1,
                "page": page,
                "per_page": per_page,
                "message": "Executive orders functionality not available"
            }
        
        # Build filters for the Azure SQL integration
        filters = {}
        if category:
            filters['category'] = category
        if search:
            filters['search'] = search
        
        # Handle special "no limit" case
        if limit == "none":
            logger.info("üîì No limit requested - fetching ALL executive orders")
            result = get_executive_orders_from_db(
                limit=None,  # No limit
                offset=0,
                filters=filters
            )
        else:
            logger.info(f"üìä Calling get_executive_orders_from_db with pagination")
            result = get_executive_orders_from_db(
                limit=per_page,
                offset=(page - 1) * per_page,
                filters=filters
            )
        
        logger.info(f"üì• Database result: success={result.get('success')}, count={result.get('count', 0)}")
        
        if not result.get('success'):
            error_msg = result.get('message', 'Failed to retrieve executive orders')
            logger.error(f"‚ùå Database query failed: {error_msg}")
            
            return {
                "results": [],
                "count": 0,
                "total_pages": 1,
                "page": page,
                "per_page": per_page,
                "error": error_msg
            }
        
        orders = result.get('results', [])
        total_count = result.get('total_count', len(orders))
        logger.info(f"üìã Got {len(orders)} orders from database, total available: {total_count}")
        
        # Apply validation and formatting
        validated_orders = []
        for i, order in enumerate(orders):
            try:
                eo_number = order.get('eo_number', '') or order.get('bill_number', '') or ''
                doc_number = order.get('document_number', '') or f"doc_{i+1}"
                
                # CRITICAL FIX: Handle reviewed field properly
                reviewed_value = order.get('reviewed')
                if reviewed_value is None:
                    reviewed = False
                elif isinstance(reviewed_value, bool):
                    reviewed = reviewed_value
                elif isinstance(reviewed_value, int):
                    reviewed = bool(reviewed_value)
                elif isinstance(reviewed_value, str):
                    reviewed = reviewed_value.lower() in ('true', '1', 'yes')
                else:
                    reviewed = False
                
                # Debug logging for reviewed field
                logger.debug(f"üîç Order {eo_number}: reviewed_value={reviewed_value} (type: {type(reviewed_value)}) -> reviewed={reviewed}")
                
                validated_order = {
                    "id": order.get('id', i+1),
                    "document_number": doc_number,
                    "eo_number": eo_number,
                    "title": order.get('title', 'Untitled Executive Order'),
                    "summary": order.get('summary', ''),
                    "signing_date": order.get('signing_date', ''),
                    "publication_date": order.get('publication_date', ''),
                    "citation": order.get('citation', ''),
                    "presidential_document_type": order.get('presidential_document_type', 'executive_order'),
                    "category": order.get('category', 'civic'),
                    "html_url": order.get('html_url', ''),
                    "pdf_url": order.get('pdf_url', ''),
                    "trump_2025_url": order.get('trump_2025_url', ''),
                    "ai_summary": order.get('ai_summary', ''),
                    "ai_executive_summary": order.get('ai_executive_summary', ''),
                    "ai_key_points": order.get('ai_key_points', ''),
                    "ai_talking_points": order.get('ai_talking_points', ''),
                    "ai_business_impact": order.get('ai_business_impact', ''),
                    "ai_potential_impact": order.get('ai_potential_impact', ''),
                    "ai_version": order.get('ai_version', ''),
                    "source": order.get('source', 'unknown'),
                    "processing_status": order.get('processing_status', 'fetched'),
                    "created_at": order.get('created_at', ''),
                    "last_updated": order.get('last_updated', ''),
                    "tags": order.get('tags', ''),
                    "highlighted": False,  # Default value
                    "reviewed": reviewed  # CRITICAL: Include reviewed field
                }
                
                validated_orders.append(validated_order)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error validating order {i}: {e}")
                continue
        
        logger.info(f"‚úÖ Validated {len(validated_orders)} orders")
        
        # Log summary of reviewed status for debugging
        reviewed_count = sum(1 for order in validated_orders if order.get('reviewed', False))
        logger.info(f"üìä Review status summary: {reviewed_count}/{len(validated_orders)} orders marked as reviewed")
        
        # Calculate pagination
        if limit == "none":
            # No pagination for unlimited requests
            total_pages = 1
            current_page = 1
        else:
            total_pages = max(1, (total_count + per_page - 1) // per_page)
            current_page = page
        
        return {
            "results": validated_orders,
            "count": len(validated_orders),
            "total_count": total_count,
            "total_pages": total_pages,
            "page": current_page,
            "per_page": per_page if limit != "none" else len(validated_orders),
            "total": total_count,
            "database_type": "Azure SQL"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Unexpected error in get_executive_orders_with_highlights: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "results": [],
            "count": 0,
            "total_pages": 1,
            "page": page,
            "per_page": per_page,
            "error": f"Unexpected error: {str(e)}"
        }

@app.post("/api/executive-orders/fetch")
async def fetch_executive_orders_unlimited(request: ExecutiveOrderFetchRequest):
    """
    UNLIMITED: Fetch ALL executive orders with NO LIMITS
    """
    try:
        logger.info("üöÄ Starting UNLIMITED Executive Orders fetch")
        
        # Use our unlimited fetch function
        result = await fetch_all_executive_orders_unlimited()
        
        if not result.get('success'):
            raise HTTPException(
                status_code=500,
                detail=result.get('error', 'Unlimited fetch failed')
            )
        
        orders = result.get('results', [])
        logger.info(f"üì• Unlimited fetch retrieved {len(orders)} executive orders")
        
        # Enhanced AI processing if requested
        ai_successful = 0
        ai_failed = 0
        
        if request.with_ai and enhanced_ai_client:
            logger.info("ü§ñ Processing with enhanced AI...")
            
            for i, order in enumerate(orders, 1):
                try:
                    if i % 10 == 0:
                        logger.info(f"ü§ñ AI processing: {i}/{len(orders)}")
                    
                    title = order.get('title', '')
                    summary = order.get('summary', '')
                    content = f"Title: {title}\nSummary: {summary}"
                    
                    # Run AI analysis
                    executive_summary = await enhanced_ai_analysis(content, PromptType.EXECUTIVE_SUMMARY)
                    talking_points = await enhanced_ai_analysis(content, PromptType.KEY_TALKING_POINTS)
                    business_impact = await enhanced_ai_analysis(content, PromptType.BUSINESS_IMPACT)
                    
                    # Add AI results to order
                    order['ai_summary'] = executive_summary
                    order['ai_executive_summary'] = executive_summary
                    order['ai_talking_points'] = talking_points
                    order['ai_key_points'] = talking_points
                    order['ai_business_impact'] = business_impact
                    order['ai_potential_impact'] = business_impact
                    order['ai_version'] = 'enhanced_azure_openai_v3'
                    
                    ai_successful += 1
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è AI processing failed for order {i}: {e}")
                    ai_failed += 1
                    continue
        
        # Save to database if requested
        saved_count = 0
        if request.save_to_db and EXECUTIVE_ORDERS_AVAILABLE:
            try:
                logger.info(f"üíæ Saving {len(orders)} orders to database...")
                saved_count = save_executive_orders_to_db(orders)
                logger.info(f"‚úÖ Successfully saved {saved_count} orders to database")
            except Exception as save_error:
                logger.error(f"‚ùå Error saving to database: {save_error}")
        
        return {
            "success": True,
            "message": f"UNLIMITED FETCH: Retrieved all {len(orders)} executive orders",
            "orders_fetched": len(orders),
            "orders_saved": saved_count,
            "total_found": result.get('total_found', len(orders)),
            "ai_successful": ai_successful,
            "ai_failed": ai_failed,
            "ai_analysis_enabled": request.with_ai and enhanced_ai_client is not None,
            "method": "unlimited_federal_register_api",
            "no_limits_applied": True,
            "pages_fetched": result.get('pages_fetched', 1),
            "date_range": result.get('date_range_used', 'Inauguration to today')
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in unlimited fetch endpoint: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Unlimited fetch failed: {str(e)}"
        )

@app.post("/api/fetch-executive-orders-simple")
async def fetch_executive_orders_simple_endpoint(request: ExecutiveOrderFetchRequest):
    """Legacy endpoint for backward compatibility"""
    try:
        logger.info("üîÑ Legacy fetch executive orders endpoint - calling unlimited fetch")
        result = await fetch_executive_orders_unlimited(request)
        return result
    except Exception as e:
        logger.error(f"‚ùå Error in legacy fetch: {e}")
        return {
            "success": False,
            "message": str(e)
        }

@app.post("/api/executive-orders/run-pipeline")
async def run_unlimited_executive_orders_pipeline(request: dict = None):
    """Run the complete executive orders pipeline with database checking - ENHANCED"""
    try:
        logger.info("üöÄ Starting Enhanced Executive Orders Pipeline with Database Check")
        
        if not SIMPLE_EO_AVAILABLE:
            return {
                "success": False,
                "message": "Simple Executive Orders API not available"
            }
        
        # Parse request parameters with enhanced options
        force_fetch = False
        fetch_only_new = True
        
        if request:
            force_fetch = request.get('force_fetch', False)
            fetch_only_new = request.get('fetch_only_new', True)
        
        logger.info(f"üìã Enhanced Pipeline parameters:")
        logger.info(f"   - force_fetch: {force_fetch}")
        logger.info(f"   - fetch_only_new: {fetch_only_new}")
        
        # Use the enhanced integration with database checking
        result = await fetch_executive_orders_simple_integration(
            start_date="2025-01-20",
            end_date=None,
            with_ai=True,
            limit=None,
            period=None,
            save_to_db=True,
            force_fetch=force_fetch  # Pass the force_fetch parameter
        )
        
        if not result.get('success'):
            error_msg = result.get('error', 'Unknown error')
            logger.warning(f"‚ö†Ô∏è Enhanced pipeline failed: {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "orders_fetched": 0,
                "orders_saved": 0
            }
        
        orders = result.get('results', [])
        total_found = result.get('total_found', len(orders))
        fetch_performed = result.get('fetch_performed', False)
        database_was_current = result.get('database_was_current', False)
        
        logger.info(f"üì• Enhanced pipeline processed {len(orders)} executive orders")
        logger.info(f"üìä Total found: {total_found}")
        logger.info(f"üîÑ Fetch performed: {fetch_performed}")
        logger.info(f"üíæ Database was current: {database_was_current}")
        
        return {
            "success": True,
            "message": result.get('message', f"Enhanced pipeline completed - processed {len(orders)} orders"),
            "orders_fetched": len(orders),
            "orders_saved": result.get('orders_saved', 0),
            "total_found": total_found,
            "ai_analysis_enabled": result.get('ai_analysis_enabled', False),
            "ai_successful": result.get('ai_successful', 0),
            "ai_failed": result.get('ai_failed', 0),
            "date_range_used": result.get('date_range_used'),
            "method": "enhanced_federal_register_with_database_check",
            
            # Enhanced database check info
            "fetch_performed": fetch_performed,
            "fetch_reason": result.get('fetch_reason', 'unknown'),
            "database_was_current": database_was_current,
            "new_orders_fetched": result.get('new_orders_fetched', 0),
            "database_count_before": result.get('database_count_before', 0),
            "federal_count": result.get('federal_count', 0),
            "processing_method": result.get('processing_method', 'enhanced'),
            
            # Backward compatibility
            "pipeline_type": "enhanced_with_database_check",
            "database_integration": "azure_sql_with_checking"
        }
            
    except Exception as e:
        logger.error(f"‚ùå Error in enhanced executive orders pipeline: {e}")
        return {
            "success": False,
            "message": f"Enhanced pipeline error: {str(e)}",
            "orders_fetched": 0,
            "orders_saved": 0,
            "error_type": type(e).__name__
        }
    else:
        logger.warning("‚ö†Ô∏è No orders to save or database not available")
        return {
            "success": len(orders) > 0,
            "message": f"Pipeline completed - found {len(orders)} orders but database not available" if orders else "No orders found",
            "orders_fetched": len(orders),
            "orders_saved": 0,
            "database_available": EXECUTIVE_ORDERS_AVAILABLE
        }
    
# Also add this new endpoint for explicit database checking
@app.get("/api/executive-orders/check-database-status")
async def check_database_status():
    """Check database status and compare with Federal Register"""
    try:
        logger.info("üîç Checking database status and Federal Register comparison")
        
        if not SIMPLE_EO_AVAILABLE:
            return {
                "success": False,
                "message": "Simple Executive Orders API not available"
            }
        
        from simple_executive_orders import SimpleExecutiveOrders
        
        simple_eo = SimpleExecutiveOrders()
        
        # Get comprehensive fetch decision
        fetch_decision = simple_eo.should_fetch_orders(force_fetch=False)
        
        # Also get database details
        db_check = simple_eo.check_database_for_existing_orders()
        
        return {
            "success": True,
            "database_status": {
                "table_exists": db_check.get('table_exists', False),
                "count": db_check.get('count', 0),
                "latest_date": db_check.get('latest_date'),
                "latest_eo_number": db_check.get('latest_eo_number'),
                "latest_title": db_check.get('latest_title')
            },
            "federal_register_status": {
                "count": fetch_decision.get('federal_count', 0),
                "api_accessible": fetch_decision.get('federal_count') is not None
            },
            "comparison": {
                "needs_fetch": fetch_decision.get('should_fetch', False),
                "reason": fetch_decision.get('reason', 'unknown'),
                "new_orders_available": fetch_decision.get('new_orders_available', 0),
                "database_up_to_date": not fetch_decision.get('should_fetch', True)
            },
            "recommendations": {
                "should_run_pipeline": fetch_decision.get('should_fetch', False),
                "force_fetch_available": True,
                "message": fetch_decision.get('message', 'Status check completed')
            },
            "last_checked": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error checking database status: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": f"Database status check failed: {str(e)}"
        }

@app.get("/api/executive-orders/check-count")
async def check_executive_orders_count():
    """Check Federal Register for total count and compare with database count"""
    try:
        # Get count from Federal Register API
        federal_register_count = await get_federal_register_count()
        
        # Get count from database
        database_count = await get_database_count()
        
        # Calculate difference
        new_orders_available = max(0, federal_register_count - database_count)
        needs_fetch = new_orders_available > 0
        
        logger.info(f"üìä Count Check - Federal Register: {federal_register_count}, Database: {database_count}, New: {new_orders_available}")
        
        return {
            "success": True,
            "federal_register_count": federal_register_count,
            "database_count": database_count,
            "new_orders_available": new_orders_available,
            "needs_fetch": needs_fetch,
            "last_checked": datetime.now().isoformat(),
            "message": f"Found {new_orders_available} new executive orders available" if needs_fetch else "Database is up to date"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error checking counts: {e}")
        return {
            "success": False,
            "error": str(e),
            "federal_register_count": 0,
            "database_count": 0,
            "new_orders_available": 0,
            "needs_fetch": False,
            "message": "Error checking for updates"
        }

# ===============================
# CATEGORY & REVIEW UPDATE ENDPOINTS
# ===============================
# Replace your category update endpoint in main.py with this corrected version:

@app.patch("/api/executive-orders/{order_id}/category")
async def update_executive_order_category(order_id: str, request: dict):
    """Update the category of an executive order"""
    try:
        logger.info(f"üîÑ Updating category for executive order: {order_id}")
        
        # Get the new category from the request
        new_category = request.get('category')
        if not new_category:
            raise HTTPException(
                status_code=400,
                detail="Category is required"
            )
        
        # UPDATED: Add "all_practice_areas" to valid categories
        valid_categories = [
            'civic', 'healthcare', 'education', 'engineering', 'business',
            'environment', 'finance', 'labor', 'transportation', 'agriculture', 
            'criminal_justice', 'not_applicable', 'all_practice_areas'  # <-- ADDED THIS
        ]
        
        if new_category not in valid_categories:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid category. Must be one of: {', '.join(valid_categories)}"
            )
        
        # Clean up the order_id (remove 'eo-' prefix if present)
        clean_order_id = order_id.replace('eo-', '') if order_id.startswith('eo-') else order_id
        logger.info(f"üìù Cleaned order ID: {clean_order_id}, new category: {new_category}")
        
        # Call the database function
        try:
            from executive_orders_db import update_executive_order_category_in_db
            
            update_success = update_executive_order_category_in_db(clean_order_id, new_category)
            
            if update_success:
                logger.info(f"‚úÖ Successfully updated category for order {clean_order_id} to {new_category}")
                return {
                    "success": True,
                    "message": f"Category updated to {new_category}",
                    "order_id": order_id,
                    "new_category": new_category
                }
            else:
                logger.warning(f"‚ö†Ô∏è Failed to update category for order {clean_order_id}")
                raise HTTPException(
                    status_code=404,
                    detail=f"Executive order not found or update failed: {order_id}"
                )
                
        except ImportError:
            logger.error("‚ùå Could not import update_executive_order_category_in_db function")
            raise HTTPException(
                status_code=500,
                detail="Database function not available"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error updating category for order {order_id}: {e}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail=f"Failed to update category: {str(e)}"
        )


# REPLACE your review endpoint in main.py with this fixed version:

@app.patch("/api/executive-orders/{id}/review")
async def update_executive_order_review_status(
    id: str,
    request: dict
):
    """Update review status for executive order - FIXED ID HANDLING"""
    try:
        reviewed = request.get('reviewed', False)
        
        print(f"üîç BACKEND: Received executive order ID: '{id}'")
        print(f"üîç BACKEND: Setting reviewed to: {reviewed}")
        
        # FIXED: Strip 'eo-' prefix if present
        clean_id = id.replace('eo-', '') if id.startswith('eo-') else id
        print(f"üîç BACKEND: Cleaned ID for database search: '{clean_id}'")
        
        from database_connection import get_db_connection
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # Search using the cleaned ID (without eo- prefix)
            search_attempts = [
                ("Direct ID match", "SELECT id FROM dbo.executive_orders WHERE id = ?", clean_id),
                ("EO number match", "SELECT id FROM dbo.executive_orders WHERE eo_number = ?", clean_id),
                ("Document number match", "SELECT id FROM dbo.executive_orders WHERE document_number = ?", clean_id),
                ("String ID match", "SELECT id FROM dbo.executive_orders WHERE CAST(id AS VARCHAR) = ?", str(clean_id)),
                ("String EO number match", "SELECT id FROM dbo.executive_orders WHERE CAST(eo_number AS VARCHAR) = ?", str(clean_id)),
                ("String document number match", "SELECT id FROM dbo.executive_orders WHERE CAST(document_number AS VARCHAR) = ?", str(clean_id))
            ]
            
            found_record_id = None
            for attempt_name, query, param in search_attempts:
                try:
                    print(f"üîç BACKEND: Trying {attempt_name} with param: '{param}'")
                    cursor.execute(query, param)
                    result = cursor.fetchone()
                    if result:
                        found_record_id = result[0]
                        print(f"‚úÖ BACKEND: Found record with {attempt_name}, database ID: {found_record_id}")
                        break
                    else:
                        print(f"‚ùå BACKEND: No match with {attempt_name}")
                except Exception as e:
                    print(f"‚ùå BACKEND: Error with {attempt_name}: {e}")
            
            if not found_record_id:
                print(f"‚ùå BACKEND: Could not find any executive order for ID: '{id}' (cleaned: '{clean_id}')")
                cursor.close()
                raise HTTPException(status_code=404, detail=f"Executive order not found for ID: {id}")
            
            # Update the record
            print(f"üîÑ BACKEND: Updating record ID {found_record_id} with reviewed={reviewed}")
            update_query = "UPDATE dbo.executive_orders SET reviewed = ?, last_updated = GETUTCDATE() WHERE id = ?"
            cursor.execute(update_query, reviewed, found_record_id)
            rows_affected = cursor.rowcount
            
            print(f"üìä BACKEND: Updated {rows_affected} rows")
            
            if rows_affected == 0:
                cursor.close()
                raise HTTPException(status_code=404, detail="No rows were updated")
            
            cursor.close()
        
        print(f"‚úÖ BACKEND: Successfully updated executive order {found_record_id} review status to {reviewed}")
        
        return {
            "success": True,
            "message": f"Review status updated to {reviewed}",
            "id": id,
            "database_id": found_record_id,
            "reviewed": reviewed
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating executive order review status: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update review status: {str(e)}")

# ===============================
# STATE LEGISLATION ENDPOINTS
# ===============================
@app.get("/api/state-legislation")
async def get_state_legislation_endpoint(
    state: Optional[str] = Query(None, description="State abbreviation or full name"),
    category: Optional[str] = Query(None, description="Filter by category"),
    limit: int = Query(100, description="Maximum number of results"),
    offset: int = Query(0, description="Number of results to skip"),
    search: Optional[str] = Query(None, description="Search in title and description")
):
    """
    THIS IS THE ENDPOINT YOUR STATEPAGE.JSX IS CALLING
    Get existing state legislation from the database
    """
    try:
        logger.info(f"üîç BACKEND: get_state_legislation called:")
        logger.info(f"   - state: '{state}', category: '{category}', limit: {limit}, search: '{search}'")
        
        if not AZURE_SQL_AVAILABLE:
            return {
                "results": [],
                "count": 0,
                "total_count": 0,
                "success": False,
                "error": "Database not available"
            }
        
        # Build filters
        filters = {}
        if state:
            filters['state'] = state
        if category and category != 'all':
            filters['category'] = category
        if search:
            filters['search'] = search
        
        # Get data from database
        result = get_state_legislation_from_db(
            limit=limit,
            offset=offset,
            filters=filters
        )
        
        if not result.get('success'):
            error_msg = result.get('message', 'Failed to retrieve state legislation')
            
            return {
                "results": [],
                "count": 0,
                "total_count": 0,
                "state": state,
                "category": category,
                "search": search,
                "offset": offset,
                "limit": limit,
                "success": False,
                "error": error_msg
            }
        
        bills = result.get('results', [])
        total_count = result.get('total', 0)
        
        logger.info(f"‚úÖ BACKEND: Successfully returning {len(bills)} bills")
        
        return {
            "results": bills,
            "count": len(bills),
            "total_count": total_count,
            "state": state,
            "category": category,
            "search": search,
            "offset": offset,
            "limit": limit,
            "success": True,
            "has_more": (offset + len(bills)) < total_count
        }
        
    except Exception as e:
        logger.error(f"‚ùå BACKEND: Error in get_state_legislation: {e}")
        
        return {
            "results": [],
            "count": 0,
            "total_count": 0,
            "success": False,
            "error": f"Error fetching state legislation: {str(e)}"
        }

@app.post("/api/legiscan/search-and-analyze")
async def search_and_analyze_bills_endpoint(request: LegiScanSearchRequest):
    """
    Search and analyze bills using LegiScan API with enhanced AI and one-by-one processing
    """
    try:
        logger.info(f"üîç BACKEND: search-and-analyze called:")
        logger.info(f"   - state: {request.state}, query: '{request.query}', limit: {request.limit}")
        
        # Check if we should use enhanced AI processing
        use_enhanced_ai = getattr(request, 'enhanced_ai', True) and enhanced_ai_client
        
        if use_enhanced_ai:
            logger.info("üöÄ BACKEND: Using ENHANCED AI processing")
            
            try:
                enhanced_legiscan = EnhancedLegiScanClient()
            except Exception as e:
                raise HTTPException(
                    status_code=503, 
                    detail=f"Enhanced LegiScan initialization failed: {str(e)}"
                )
            
            # Get database manager if saving to database
            db_manager = None
            if request.save_to_db and AZURE_SQL_AVAILABLE:
                try:
                    conn = get_azure_sql_connection()
                    if conn:
                        db_manager = StateLegislationDatabaseManager(conn)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è BACKEND: Database manager creation failed: {e}")
            
            # Use enhanced search and analyze
            result = await enhanced_legiscan.enhanced_search_and_analyze(
                state=request.state,
                query=request.query,
                limit=request.limit,
                with_ai=request.with_ai_analysis,
                db_manager=db_manager
            )
            
            # Close database connection if it was opened
            if db_manager and hasattr(db_manager, 'connection'):
                try:
                    db_manager.connection.close()
                except:
                    pass
            
            bills_saved = result.get('processing_results', {}).get('total_saved', 0)
            
            return {
                "success": True,
                "enhanced_ai_used": True,
                "bills_analyzed": len(result.get('bills', [])),
                "bills_saved": bills_saved,
                "workflow_used": "enhanced_one_by_one",
                "message": f"Enhanced analysis of {len(result.get('bills', []))} bills for '{request.query}' in {request.state}",
                "legiscan_result": {
                    "success": result.get('success'),
                    "query": request.query,
                    "state": request.state,
                    "total_found": result.get('bills_found', 0),
                    "timestamp": result.get('timestamp')
                },
                "processing_details": result.get('processing_results', {}),
                "ai_features": {
                    "executive_summary": "Enhanced multi-paragraph summaries",
                    "talking_points": "Exactly 5 formatted stakeholder discussion points",
                    "business_impact": "Structured risk/opportunity analysis",
                    "categorization": "Advanced 5-category classification"
                }
            }
        
        else:
            logger.info("üìä BACKEND: Using traditional LegiScan processing")
            
            # Check if traditional LegiScan API is available
            if not LEGISCAN_AVAILABLE:
                raise HTTPException(
                    status_code=503, 
                    detail="LegiScan API not available - check if legiscan_api.py file exists"
                )
            
            if not LEGISCAN_INITIALIZED:
                raise HTTPException(
                    status_code=503, 
                    detail="LegiScan API not initialized - check LEGISCAN_API_KEY in .env file"
                )
            
            # Initialize traditional LegiScan API
            try:
                legiscan_api = LegiScanAPI()
            except Exception as e:
                raise HTTPException(
                    status_code=503, 
                    detail=f"LegiScan API initialization failed: {str(e)}"
                )
            
            bills_saved = 0
            result = {}
            
            # Traditional processing workflow
            if request.process_one_by_one and request.save_to_db and AZURE_SQL_AVAILABLE:
                
                # Get AI client if AI analysis is requested
                ai_client = None
                if request.with_ai_analysis:
                    ai_client = get_ai_client()
                
                # Get database connection and create manager
                try:
                    conn = get_azure_sql_connection()
                    if not conn:
                        raise HTTPException(status_code=503, detail="Database connection failed")
                    
                    db_manager = StateLegislationDatabaseManager(conn)
                    
                    # Use the traditional one-by-one processing workflow
                    result = legiscan_api.search_and_analyze_bills(
                        state=request.state,
                        query=request.query,
                        limit=request.limit,
                        ai_client=ai_client,
                        db_manager=db_manager,
                        process_one_by_one=True
                    )
                    
                    conn.close()
                    
                    # Extract processing results
                    if result.get('processing_results'):
                        processing = result['processing_results']
                        bills_saved = processing.get('total_saved', 0)
                
                except Exception as e:
                    raise HTTPException(status_code=500, detail=f"One-by-one processing failed: {str(e)}")
                    
            else:
                # Use traditional search_and_analyze_bills method (batch way)
                result = legiscan_api.search_and_analyze_bills(
                    state=request.state,
                    query=request.query,
                    limit=request.limit
                )
                
                # Save to database if requested and bills were returned (traditional batch save)
                if request.save_to_db and result.get('bills') and AZURE_SQL_AVAILABLE:
                    bills = result['bills']
                    
                    try:
                        bills_saved = save_state_legislation_to_db(bills)
                    except Exception as e:
                        logger.warning(f"‚ùå BACKEND: Database save failed: {e}")
            
            # Prepare traditional response
            response_data = {
                "success": True,
                "enhanced_ai_used": False,
                "bills_analyzed": len(result.get('bills', [])),
                "bills_saved": bills_saved,
                "workflow_used": "one_by_one" if request.process_one_by_one else "batch",
                "message": f"Successfully analyzed {len(result.get('bills', []))} bills for '{request.query}' in {request.state}",
                "legiscan_result": {
                    "success": result.get('success'),
                    "query": request.query,
                    "state": request.state,
                    "total_found": result.get('bills_found', 0),
                    "timestamp": result.get('timestamp')
                }
            }
            
            # Add one-by-one processing details if used
            if request.process_one_by_one and result.get('processing_results'):
                processing = result['processing_results']
                response_data["processing_details"] = {
                    "total_fetched": processing.get('total_fetched', 0),
                    "total_processed": processing.get('total_processed', 0),
                    "total_saved": processing.get('total_saved', 0),
                    "errors": processing.get('errors', []),
                    "ai_analysis_used": request.with_ai_analysis and bool(get_ai_client())
                }
            
            return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå BACKEND: Error in search-and-analyze: {e}")
        raise HTTPException(status_code=500, detail=f"Search and analyze failed: {str(e)}")

@app.post("/api/legiscan/enhanced-search-and-analyze")
async def enhanced_search_and_analyze_endpoint(request: LegiScanSearchRequest):
    """
    NEW: Enhanced search and analyze using ai.py integration
    """
    try:
        logger.info(f"üöÄ ENHANCED: search-and-analyze called:")
        logger.info(f"   - state: {request.state}, query: '{request.query}', enhanced_ai: {getattr(request, 'enhanced_ai', True)}")
        
        # Check if enhanced AI is available
        if not enhanced_ai_client:
            raise HTTPException(
                status_code=503, 
                detail="Enhanced AI client not available - check Azure OpenAI configuration"
            )
        
        # Initialize enhanced LegiScan client
        try:
            enhanced_legiscan = EnhancedLegiScanClient()
        except Exception as e:
            raise HTTPException(
                status_code=503, 
                detail=f"Enhanced LegiScan initialization failed: {str(e)}"
            )
        
        # Get database manager if saving to database
        db_manager = None
        if request.save_to_db:
            try:
                conn = get_azure_sql_connection()
                if conn:
                    db_manager = StateLegislationDatabaseManager(conn)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è ENHANCED: Database manager creation failed: {e}")
        
        # Use enhanced search and analyze
        result = await enhanced_legiscan.enhanced_search_and_analyze(
            state=request.state,
            query=request.query,
            limit=request.limit,
            with_ai=getattr(request, 'enhanced_ai', True),
            db_manager=db_manager
        )
        
        # Close database connection if it was opened
        if db_manager and hasattr(db_manager, 'connection'):
            try:
                db_manager.connection.close()
            except:
                pass
        
        if not result.get('success'):
            raise HTTPException(
                status_code=500,
                detail=result.get('error', 'Enhanced search and analysis failed')
            )
        
        # Prepare enhanced response
        response_data = {
            "success": True,
            "enhanced_ai_used": True,
            "bills_analyzed": len(result.get('bills', [])),
            "bills_saved": result.get('processing_results', {}).get('total_saved', 0),
            "workflow_used": "enhanced_one_by_one",
            "message": f"Enhanced analysis of {len(result.get('bills', []))} bills for '{request.query}' in {request.state}",
            "enhanced_legiscan_result": {
                "success": result.get('success'),
                "query": request.query,
                "state": request.state,
                "total_found": result.get('bills_found', 0),
                "timestamp": result.get('timestamp')
            },
            "processing_details": result.get('processing_results', {}),
            "ai_features": {
                "executive_summary": "Enhanced multi-paragraph summaries",
                "talking_points": "Exactly 5 formatted stakeholder discussion points",
                "business_impact": "Structured risk/opportunity analysis",
                "categorization": "Advanced 5-category classification"
            }
        }
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå ENHANCED: Error in enhanced search-and-analyze: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Enhanced search and analyze failed: {str(e)}"
        )

@app.post("/api/state-legislation/fetch")
async def fetch_state_legislation_endpoint(request: StateLegislationFetchRequest):
    """Bulk fetch state legislation using LegiScan API"""
    try:
        logger.info(f"üîç BACKEND: fetch_state_legislation called:")
        logger.info(f"   - states: {request.states}, bills_per_state: {request.bills_per_state}")
        
        # Check if LegiScan API is available
        if not LEGISCAN_AVAILABLE:
            raise HTTPException(
                status_code=503, 
                detail="LegiScan API not available - check if legiscan_api.py file exists"
            )
        
        if not LEGISCAN_INITIALIZED:
            raise HTTPException(
                status_code=503, 
                detail="LegiScan API not initialized - check LEGISCAN_API_KEY in .env file"
            )
        
        # Initialize LegiScan API
        try:
            legiscan_api = LegiScanAPI()
        except Exception as e:
            raise HTTPException(
                status_code=503, 
                detail=f"LegiScan API initialization failed: {str(e)}"
            )
        
        total_fetched = 0
        total_saved = 0
        state_results = {}
        
        for state in request.states:
            try:
                # Use your existing optimized bulk fetch method
                result = legiscan_api.optimized_bulk_fetch(
                    state=state,
                    limit=request.bills_per_state,
                    recent_only=True
                )
                
                state_fetched = 0
                state_saved = 0
                
                if result.get('success') and result.get('bills'):
                    bills = result['bills']
                    state_fetched = len(bills)
                    total_fetched += state_fetched
                    
                    if request.save_to_db and AZURE_SQL_AVAILABLE:
                        try:
                            state_saved = save_state_legislation_to_db(bills)
                            total_saved += state_saved
                        except Exception as e:
                            logger.warning(f"‚ùå BACKEND: Error saving {state} bills: {e}")
                            state_saved = 0
                
                state_results[state] = {
                    "success": result.get('success', False),
                    "bills_fetched": state_fetched,
                    "bills_saved": state_saved,
                    "error": result.get('error')
                }
                
            except Exception as e:
                logger.warning(f"‚ùå BACKEND: Error processing state {state}: {e}")
                state_results[state] = {
                    "success": False,
                    "bills_fetched": 0,
                    "bills_saved": 0,
                    "error": str(e)
                }
                continue
        
        return {
            "success": True,
            "total_bills_fetched": total_fetched,
            "total_bills_saved": total_saved,
            "states_processed": len(request.states),
            "state_results": state_results,
            "message": f"Successfully processed {len(request.states)} states, fetched {total_fetched} bills, saved {total_saved} bills"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå BACKEND: Error in fetch endpoint: {e}")
        raise HTTPException(status_code=500, detail=f"Bulk fetch failed: {str(e)}")

@app.patch("/api/state-legislation/{id}/category")
async def update_state_legislation_category(id: str, request: dict):
    """Update category for state legislation"""
    try:
        category = request.get('category')
        
        if not category:
            raise HTTPException(status_code=400, detail="Category is required")
        
        # UPDATED: Add "all_practice_areas" to valid categories
        valid_categories = [
            'civic', 'healthcare', 'education', 'engineering', 'business', 
            'environment', 'finance', 'labor', 'transportation', 'agriculture', 
            'criminal_justice', 'not_applicable', 'all_practice_areas'  # <-- ADDED THIS
        ]
        
        if category not in valid_categories:
            raise HTTPException(
                status_code=400, 
                detail=f"Invalid category. Must be one of: {', '.join(valid_categories)}"
            )
        
        conn = get_azure_sql_connection()
        if not conn:
            raise HTTPException(status_code=503, detail="Database connection failed")
        
        cursor = conn.cursor()
        
        # Try to find the record multiple ways
        search_attempts = [
            ("Direct ID match", "SELECT id FROM dbo.state_legislation WHERE id = ?", id),
            ("Direct bill_id match", "SELECT id FROM dbo.state_legislation WHERE bill_id = ?", id),
            ("String ID match", "SELECT id FROM dbo.state_legislation WHERE CAST(id AS VARCHAR) = ?", str(id)),
            ("String bill_id match", "SELECT id FROM dbo.state_legislation WHERE CAST(bill_id AS VARCHAR) = ?", str(id))
        ]
        
        found_record_id = None
        for attempt_name, query, param in search_attempts:
            try:
                cursor.execute(query, param)
                result = cursor.fetchone()
                if result:
                    found_record_id = result[0]
                    break
            except Exception as e:
                continue
        
        if not found_record_id:
            conn.close()
            raise HTTPException(status_code=404, detail=f"State legislation not found for ID: {id}")
        
        # Update the record
        update_query = "UPDATE dbo.state_legislation SET category = ?, last_updated = GETDATE() WHERE id = ?"
        cursor.execute(update_query, category, found_record_id)
        rows_affected = cursor.rowcount
        
        if rows_affected == 0:
            conn.close()
            raise HTTPException(status_code=404, detail="No rows were updated")
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "message": f"Category updated to {category}",
            "id": id,
            "database_id": found_record_id,
            "category": category
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating state legislation category: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update category: {str(e)}")

@app.patch("/api/state-legislation/{id}/review")
async def update_state_legislation_review_status(id: str, request: dict):
    """Update review status for state legislation"""
    try:
        reviewed = request.get('reviewed', False)
        
        conn = get_azure_sql_connection()
        if not conn:
            raise HTTPException(status_code=503, detail="Database connection failed")
        
        cursor = conn.cursor()
        
        # Try to find the record multiple ways (same logic as category update)
        search_attempts = [
            ("Direct ID match", "SELECT id FROM dbo.state_legislation WHERE id = ?", id),
            ("Direct bill_id match", "SELECT id FROM dbo.state_legislation WHERE bill_id = ?", id),
            ("String ID match", "SELECT id FROM dbo.state_legislation WHERE CAST(id AS VARCHAR) = ?", str(id)),
            ("String bill_id match", "SELECT id FROM dbo.state_legislation WHERE CAST(bill_id AS VARCHAR) = ?", str(id))
        ]
        
        found_record_id = None
        for attempt_name, query, param in search_attempts:
            try:
                cursor.execute(query, param)
                result = cursor.fetchone()
                if result:
                    found_record_id = result[0]
                    break
            except Exception:
                continue
        
        if not found_record_id:
            conn.close()
            raise HTTPException(status_code=404, detail=f"State legislation not found for ID: {id}")
        
        # Update the record
        update_query = "UPDATE dbo.state_legislation SET reviewed = ?, last_updated = GETDATE() WHERE id = ?"
        cursor.execute(update_query, reviewed, found_record_id)
        rows_affected = cursor.rowcount
        
        if rows_affected == 0:
            conn.close()
            raise HTTPException(status_code=404, detail="No rows were updated")
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "message": f"Review status updated to {reviewed}",
            "id": id,
            "database_id": found_record_id,
            "reviewed": reviewed
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating state legislation review status: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update review status: {str(e)}")

# ===============================
# UTILITY ENDPOINTS FOR STATE LEGISLATION
# ===============================
@app.get("/api/state-legislation/states")
async def get_available_states():
    """Get list of states that have data in the database"""
    try:
        if not AZURE_SQL_AVAILABLE:
            return {
                "success": False,
                "message": "Database not available",
                "states": {},
                "total_states": 0
            }
        
        conn = get_azure_sql_connection()
        if not conn:
            return {
                "success": False,
                "message": "Database connection failed",
                "states": {},
                "total_states": 0
            }
        
        cursor = conn.cursor()
        
        # Get distinct states from database
        query = """
        SELECT state, state_abbr, COUNT(*) as bill_count
        FROM dbo.state_legislation
        WHERE state IS NOT NULL AND state != ''
        GROUP BY state, state_abbr
        ORDER BY state
        """
        
        cursor.execute(query)
        states_data = {}
        
        for row in cursor.fetchall():
            state, state_abbr, count = row
            if state:
                states_data[state] = {
                    "full_name": state,
                    "abbreviation": state_abbr,
                    "bill_count": count
                }
        
        cursor.close()
        conn.close()
        
        return {
            "success": True,
            "states": states_data,
            "total_states": len(states_data)
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "states": {},
            "total_states": 0
        }

@app.get("/api/state-legislation/stats")
async def get_state_legislation_stats():
    """Get overall statistics about the state legislation database"""
    try:
        if not AZURE_SQL_AVAILABLE:
            return {
                "success": False,
                "message": "Database not available",
                "total_bills": 0
            }
        
        conn = get_azure_sql_connection()
        if not conn:
            return {
                "success": False,
                "message": "Database connection failed",
                "total_bills": 0
            }
        
        cursor = conn.cursor()
        
        # Get total bills
        cursor.execute("SELECT COUNT(*) FROM dbo.state_legislation")
        total_bills = cursor.fetchone()[0]
        
        # Count by state
        cursor.execute("""
            SELECT state, COUNT(*) as count
            FROM dbo.state_legislation
            WHERE state IS NOT NULL AND state != ''
            GROUP BY state
            ORDER BY count DESC
        """)
        state_counts = {}
        for row in cursor.fetchall():
            state, count = row
            state_counts[state] = count
        
        # Count by category
        cursor.execute("""
            SELECT category, COUNT(*) as count
            FROM dbo.state_legislation
            WHERE category IS NOT NULL AND category != ''
            GROUP BY category
            ORDER BY count DESC
        """)
        category_counts = {}
        for row in cursor.fetchall():
            category, count = row
            category_counts[category] = count
        
        # Get most recent update
        cursor.execute("""
            SELECT TOP 1 last_updated
            FROM dbo.state_legislation
            ORDER BY last_updated DESC
        """)
        latest_row = cursor.fetchone()
        last_updated = latest_row[0].isoformat() if latest_row and latest_row[0] else None
        
        cursor.close()
        conn.close()
        
        return {
            "success": True,
            "total_bills": total_bills,
            "total_states": len(state_counts),
            "total_categories": len(category_counts),
            "state_counts": state_counts,
            "category_counts": category_counts,
            "last_updated": last_updated
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "total_bills": 0
        }

# ===============================
# HIGHLIGHTS ENDPOINTS
# ===============================
@app.get("/api/highlights")
async def get_user_highlights(user_id: str = Query("1", description="User identifier")):
    """Get all highlights for a user"""
    try:
        create_highlights_table()
        highlights = get_user_highlights_direct(user_id)
        
        return {
            "success": True,
            "user_id": user_id,
            "highlights": highlights,
            "results": highlights,
            "count": len(highlights),
            "database_type": "Azure SQL",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error getting user highlights: {e}")
        return {
            "success": False,
            "error": str(e),
            "highlights": [],
            "results": []
        }

@app.post("/api/highlights")
async def add_highlight_endpoint(request: HighlightCreateRequest):
    """Add a highlight"""
    if not HIGHLIGHTS_DB_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Highlights database not available. Please ensure Azure SQL is configured."
        )
    
    try:
        create_highlights_table()
        
        # Get the item data if it's an executive order
        item_data = {}
        if request.order_type == 'executive_order' and EXECUTIVE_ORDERS_AVAILABLE:
            try:
                db_result = get_executive_orders_from_db(limit=1000, offset=0, filters={})
                if db_result.get('success'):
                    for order in db_result.get('results', []):
                        if order.get('bill_number') == request.order_id:
                            item_data = {
                                'title': order.get('title', ''),
                                'summary': order.get('summary', ''),
                                'ai_summary': order.get('ai_summary', ''),
                                'category': order.get('category', ''),
                                'state': order.get('state', ''),
                                'signing_date': order.get('introduced_date', ''),
                                'html_url': order.get('legiscan_url', ''),
                                'pdf_url': order.get('pdf_url', ''),
                                'legiscan_url': order.get('legiscan_url', '')
                            }
                            break
            except Exception as e:
                logger.warning(f"Could not get item data for highlight: {e}")
        
        success = add_highlight_direct(
            user_id=str(request.user_id), 
            order_id=request.order_id, 
            order_type=request.order_type,
            item_data=item_data
        )
        
        if success:
            return {
                "success": True,
                "message": "Highlight added successfully",
                "user_id": request.user_id,
                "order_id": request.order_id,
                "order_type": request.order_type
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to add highlight")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error adding highlight: {e}")
        raise HTTPException(status_code=500, detail=f"Error adding highlight: {str(e)}")

@app.delete("/api/highlights/{order_id}")
async def remove_highlight_endpoint(
    order_id: str,
    user_id: str = Query("1", description="User identifier"),
    order_type: Optional[str] = Query(None, description="Order type for more specific removal")
):
    """Remove a highlight"""
    if not HIGHLIGHTS_DB_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Highlights database not available. Please ensure Azure SQL is configured."
        )
    
    try:
        success = remove_highlight_direct(user_id, order_id, order_type)
        
        if success:
            return {
                "success": True,
                "message": "Highlight removed successfully",
                "user_id": user_id,
                "order_id": order_id
            }
        else:
            raise HTTPException(status_code=404, detail="Highlight not found")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error removing highlight: {e}")
        raise HTTPException(status_code=500, detail=f"Error removing highlight: {str(e)}")

# ===============================
# MAIN STARTUP
# ===============================
if __name__ == "__main__":
    import uvicorn
    logger.info("üåê Starting Complete LegislationVue API v16.0.0")
    logger.info("=" * 80)
    
    logger.info("üöÄ ALL FUNCTIONALITY PRESERVED:")
    logger.info("   ‚úÖ UNLIMITED Federal Register fetching (no 20 order limit)")
    logger.info("   ‚úÖ Executive Orders: Full pipeline with AI")
    logger.info("   ‚úÖ State Legislation: Enhanced AI + Traditional workflows")
    logger.info("   ‚úÖ LegiScan Integration: Both enhanced and traditional")
    logger.info("   ‚úÖ Highlights System: Full CRUD operations")
    logger.info("   ‚úÖ Category Updates: PATCH endpoints")
    logger.info("   ‚úÖ Review Status: PATCH endpoints")
    logger.info("   ‚úÖ Count Checking: Federal Register vs Database")
    logger.info("   ‚úÖ Enhanced AI: Multi-format analysis")
    logger.info("   ‚úÖ One-by-one Processing: Bill-by-bill workflows")
    logger.info("   ‚úÖ Database Integration: Azure SQL")
    logger.info("   ‚úÖ All Original Endpoints: Preserved and working")
    
    logger.info("\nüìã COMPLETE ENDPOINT LIST:")
    logger.info("   ‚Ä¢ GET  / - Root status")
    logger.info("   ‚Ä¢ GET  /api/status - System status")
    logger.info("   ‚Ä¢ GET  /api/executive-orders - Get executive orders")
    logger.info("   ‚Ä¢ POST /api/executive-orders/fetch - Unlimited fetch")
    logger.info("   ‚Ä¢ POST /api/fetch-executive-orders-simple - Legacy endpoint")
    logger.info("   ‚Ä¢ POST /api/executive-orders/run-pipeline - Full pipeline")
    logger.info("   ‚Ä¢ GET  /api/executive-orders/check-count - Count comparison")
    logger.info("   ‚Ä¢ PATCH /api/executive-orders/{id}/category - Update category")
    logger.info("   ‚Ä¢ PATCH /api/executive-orders/{id}/review - Update review")
    logger.info("   ‚Ä¢ GET  /api/state-legislation - Get state bills")
    logger.info("   ‚Ä¢ POST /api/legiscan/search-and-analyze - Search & analyze")
    logger.info("   ‚Ä¢ POST /api/legiscan/enhanced-search-and-analyze - Enhanced AI")
    logger.info("   ‚Ä¢ POST /api/state-legislation/fetch - Bulk fetch")
    logger.info("   ‚Ä¢ PATCH /api/state-legislation/{id}/category - Update category")
    logger.info("   ‚Ä¢ PATCH /api/state-legislation/{id}/review - Update review")
    logger.info("   ‚Ä¢ GET  /api/state-legislation/states - Available states")
    logger.info("   ‚Ä¢ GET  /api/state-legislation/stats - Statistics")
    logger.info("   ‚Ä¢ GET  /api/highlights - Get highlights")
    logger.info("   ‚Ä¢ POST /api/highlights - Add highlight")
    logger.info("   ‚Ä¢ DELETE /api/highlights/{id} - Remove highlight")
    
    # Test database connection
    try:
        if test_database_connection():
            logger.info("‚úÖ Database connection successful!")
            if create_highlights_table():
                logger.info("‚úÖ Highlights table ready!")
        else:
            logger.warning("‚ùå Database connection failed")
    except Exception as e:
        logger.error(f"‚ùå Database connection test error: {e}")
    
    # Test Enhanced AI
    if enhanced_ai_client:
        logger.info("‚úÖ Enhanced AI client ready!")
    else:
        logger.warning("‚ö†Ô∏è Enhanced AI client not available")
    
    logger.info("üéØ Starting server with ALL functionality preserved...")
    uvicorn.run(app, host="0.0.0.0", port=8000)